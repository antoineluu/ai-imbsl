{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils_pp import replace_cell_names_with_id\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oneil 13.13536 (234560, 6) \n",
      " cell_line      object\n",
      "drugA_name     object\n",
      "drugB_name     object\n",
      "drugA_conc    float64\n",
      "drugB_conc    float64\n",
      "target        float64\n",
      "dtype: object\n",
      "drug_feat 0.407338 (42, 2416)\n",
      "cell_feat 0.686136 (32, 5011)\n"
     ]
    }
   ],
   "source": [
    "columns = [\"cell_line\", \"drugA_name\", \"drugB_name\", \"drugA_conc\", \"drugB_conc\", \"target\"]\n",
    "df_train = pd.read_csv(\"../data_raw/oneil.csv\", usecols=(1,2,3,4,5,12)).iloc[:,[0,1,3,2,4,5]].set_axis(columns, axis=1)\n",
    "# df_train[\"cell_line\"]\n",
    "df_test = pd.read_csv(\"../data/test_yosua.csv\").set_axis(columns + [\"std\"], axis=1).convert_dtypes()\n",
    "\n",
    "drug_data = pd.read_pickle(\"../data/drug_data.pkl.compress\", compression=\"gzip\")\n",
    "cell_data = pd.read_pickle(\"../data/cell_line_data.pkl.compress\", compression=\"gzip\")\n",
    "\n",
    "df_train = replace_cell_names_with_id(dataframe=df_train, mapping_file=\"../data/mappingccl.csv\")\n",
    "df_test = replace_cell_names_with_id(dataframe=df_test, mapping_file=\"../data/mappingccl.csv\")\n",
    "df_train = df_train[df_train.cell_line.isin(cell_data.index)]\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, shuffle=True)\n",
    "cell_data = cell_data[cell_data.index.isin(pd.concat([df_train.cell_line, df_test.cell_line]))]\n",
    "print(\"oneil\", df_train.memory_usage().sum()/1e6, df_train.shape,\"\\n\", df_train.dtypes)\n",
    "print(\"drug_feat\", drug_data.memory_usage().sum()/1e6, drug_data.shape)\n",
    "print(\"cell_feat\", cell_data.memory_usage().sum()/1e6, cell_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([256, 9845]) torch.Size([256, 1])\n",
      "[250. 250. 250. 250. 250. 250. 250.]\n"
     ]
    }
   ],
   "source": [
    "class Dataset_from_pd(Dataset):\n",
    "    def __init__(self, drug_comb_data, drug_feat, cell_feat):\n",
    "        self.drug_comb_data = drug_comb_data.to_numpy()\n",
    "        self.drug_feat = drug_feat.to_numpy()\n",
    "        self.cell_feat = cell_feat.to_numpy()\n",
    "        self.drug_mapping = pd.Series(range(len(self.drug_feat)), index=drug_feat.index).to_dict()\n",
    "        self.cell_mapping = pd.Series(range(len(self.cell_feat)), index=cell_feat.index).to_dict()\n",
    "        # print(self.cell_mapping, self.drug_mapping)\n",
    "\n",
    "        print()\n",
    "    def __len__(self):\n",
    "        return len(self.drug_comb_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        combi = self.drug_comb_data[idx]\n",
    "        drug_A = self.drug_feat[self.drug_mapping[combi[1]]]\n",
    "        drug_B = self.drug_feat[self.drug_mapping[combi[2]]]\n",
    "        cell_line = self.cell_feat[self.cell_mapping[combi[0]]]\n",
    "        # if np.isnan(drug_A).sum() >0 or np.isnan(drug_B).sum() >0 or np.isnan(cell_line).sum() > 0:             \n",
    "        #     print(np.isnan(drug_A),np.isnan(drug_A).sum(),\"\\n\", np.isnan(drug_B),np.isnan(drug_B).sum(), \"\\n\", np.isnan(cell_line),np.isnan(cell_line).sum())\n",
    "        #     raise NotImplementedError\n",
    "        return np.concatenate([drug_A, drug_B, cell_line, combi[3:5].astype(\"float32\")], dtype=\"float32\"), combi[5:6].astype(\"float32\")\n",
    "\n",
    "train_set  = Dataset_from_pd(df_train, drug_data, cell_data)\n",
    "train_dl = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "xi, yi = next(iter(train_dl))\n",
    "print(xi.shape, yi.shape)\n",
    "# print(np.argwhere(xi>1e2))\n",
    "# print(tuple(np.argwhere(xi>100)))\n",
    "print(xi.numpy()[tuple(np.argwhere(xi>100))])\n",
    "# print(xi.numpy()[:,tuple(np.argwhere(xi>100))[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, h_sizes):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(h_sizes)-1):\n",
    "            self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
    "            self.hidden.append(nn.Dropout(0.2))\n",
    "            self.hidden.append(nn.ReLU())\n",
    "        self.hidden.append(nn.Linear(h_sizes[-1], 1))\n",
    "    def forward(self, x):\n",
    "        for lay in self.hidden:\n",
    "            # print(torch.sum(torch.isnan(x)))\n",
    "            # print(torch.sum(x>1e3))\n",
    "            x = lay(x)\n",
    "        return x\n",
    "model = MLP([xi.shape[1],32])\n",
    "yi = model.forward(xi)\n",
    "print(yi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, training_loader, optimizer, loss_fn):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() / inputs.shape[0]\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss), outputs[0][0].item(), labels[0][0].item())\n",
    "            # tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1            [-1, 1024, 256]       2,520,576\n",
      "           Dropout-2            [-1, 1024, 256]               0\n",
      "              ReLU-3            [-1, 1024, 256]               0\n",
      "            Linear-4            [-1, 1024, 256]          65,792\n",
      "           Dropout-5            [-1, 1024, 256]               0\n",
      "              ReLU-6            [-1, 1024, 256]               0\n",
      "            Linear-7            [-1, 1024, 256]          65,792\n",
      "           Dropout-8            [-1, 1024, 256]               0\n",
      "              ReLU-9            [-1, 1024, 256]               0\n",
      "           Linear-10            [-1, 1024, 128]          32,896\n",
      "          Dropout-11            [-1, 1024, 128]               0\n",
      "             ReLU-12            [-1, 1024, 128]               0\n",
      "           Linear-13            [-1, 1024, 128]          16,512\n",
      "          Dropout-14            [-1, 1024, 128]               0\n",
      "             ReLU-15            [-1, 1024, 128]               0\n",
      "           Linear-16            [-1, 1024, 128]          16,512\n",
      "          Dropout-17            [-1, 1024, 128]               0\n",
      "             ReLU-18            [-1, 1024, 128]               0\n",
      "           Linear-19             [-1, 1024, 64]           8,256\n",
      "          Dropout-20             [-1, 1024, 64]               0\n",
      "             ReLU-21             [-1, 1024, 64]               0\n",
      "           Linear-22             [-1, 1024, 64]           4,160\n",
      "          Dropout-23             [-1, 1024, 64]               0\n",
      "             ReLU-24             [-1, 1024, 64]               0\n",
      "           Linear-25             [-1, 1024, 64]           4,160\n",
      "          Dropout-26             [-1, 1024, 64]               0\n",
      "             ReLU-27             [-1, 1024, 64]               0\n",
      "           Linear-28              [-1, 1024, 1]              65\n",
      "================================================================\n",
      "Total params: 2,734,721\n",
      "Trainable params: 2,734,721\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 38.46\n",
      "Forward/backward pass size (MB): 31.51\n",
      "Params size (MB): 10.43\n",
      "Estimated Total Size (MB): 80.40\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "EPOCH 1:\n",
      "  batch 10 loss: 0.00038221998838707807 0.009777426719665527 0.49300000071525574 1024\n",
      "  batch 20 loss: 0.0003737040620762855 0.02237367257475853 0.9340000152587891 1024\n",
      "  batch 30 loss: 0.0003772418771404773 0.0029342472553253174 0.5009999871253967 1024\n",
      "  batch 40 loss: 0.0003658316069049761 0.03352414444088936 0.6650000214576721 1024\n",
      "  batch 50 loss: 0.00037326670426409694 0.02865651249885559 0.017000000923871994 1024\n",
      "  batch 60 loss: 0.0003637212503235787 0.0658554658293724 0.0430000014603138 1024\n",
      "  batch 70 loss: 0.00036804734845645725 0.057896122336387634 0.8510000109672546 1024\n",
      "  batch 80 loss: 0.0003699344175402075 0.049258820712566376 0.8019999861717224 1024\n",
      "  batch 90 loss: 0.00036789326695725323 0.018874693661928177 0.2029999941587448 1024\n",
      "  batch 100 loss: 0.00035139499814249573 0.06838002800941467 0.36000001430511475 1024\n",
      "  batch 110 loss: 0.00035188016190659257 0.0630442202091217 0.9990000128746033 1024\n",
      "  batch 120 loss: 0.0003484597167698666 0.03986899554729462 0.6470000147819519 1024\n",
      "  batch 130 loss: 0.0003475130419246852 0.06695463508367538 0.3540000021457672 1024\n",
      "  batch 140 loss: 0.00033821814868133514 0.059403933584690094 0.1469999998807907 1024\n",
      "  batch 150 loss: 0.00032823439687490463 0.05396408587694168 0.4129999876022339 1024\n",
      "  batch 160 loss: 0.0003117481479421258 0.13888530433177948 0.7509999871253967 1024\n",
      "  batch 170 loss: 0.00030613059061579406 0.09449902921915054 0.014000000432133675 1024\n",
      "  batch 180 loss: 0.00028684738208539784 0.10494087636470795 0.012000000104308128 1024\n",
      "  batch 190 loss: 0.0002705152000999078 0.13037866353988647 0.06400000303983688 1024\n",
      "  batch 200 loss: 0.00025144098326563836 0.11764881014823914 1.065999984741211 1024\n",
      "  batch 210 loss: 0.00022594773618038743 0.329353004693985 0.9819999933242798 1024\n",
      "  batch 220 loss: 0.00019682679267134516 0.16358457505702972 0.6019999980926514 1024\n",
      "  batch 230 loss: 0.00047089810395846144 0.15324291586875916 0.3610000014305115 64\n",
      "LOSS train 0.00047089810395846144 valid 0.00016212165064644068\n",
      "[[0.10679447]] [[1.0249797]]\n",
      "[[0.10742896]] [[0.7882507]]\n",
      "[[0.10806315]] [[0.7118246]]\n",
      "[[0.10867722]] [[0.54228866]]\n",
      "[[0.09566303]] [[0.970456]]\n",
      "[[0.09627649]] [[0.7996898]]\n",
      "[[0.09687007]] [[0.52382165]]\n",
      "[[0.09744529]] [[0.2116317]]\n",
      "[[0.08695777]] [[1.9516927]]\n",
      "[[0.08716243]] [[1.4921523]]\n",
      "[[0.08736466]] [[1.4859641]]\n",
      "[[0.0875762]] [[1.4145942]]\n",
      "[[0.09659833]] [[0.36284554]]\n",
      "[[0.09725128]] [[0.01175009]]\n",
      "[[0.09790726]] [[0.00413306]]\n",
      "[[0.09860384]] [[0.01023069]]\n",
      "[[0.08803622]] [[1.5044664]]\n",
      "[[0.08834207]] [[1.1610321]]\n",
      "[[0.0886618]] [[1.0217108]]\n",
      "[[0.08898497]] [[1.0783128]]\n",
      "[[0.08596671]] [[1.508316]]\n",
      "[[0.08613244]] [[1.3742086]]\n",
      "[[0.08630776]] [[1.138154]]\n",
      "[[0.08647683]] [[0.96429497]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "train_set  = Dataset_from_pd(df_train, drug_data, cell_data)\n",
    "val_set = Dataset_from_pd(df_val, drug_data, cell_data)\n",
    "test_set  = Dataset_from_pd(df_test, drug_data, cell_data)\n",
    "train_dl = DataLoader(train_set, batch_size=batch_size)\n",
    "xi, yi = next(iter(train_dl))\n",
    "val_dl = DataLoader(val_set, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_set)\n",
    "\n",
    "model = MLP([xi.shape[1],256,256,256, 128,128,128,64,64,64])\n",
    "print(summary(model.to(\"cuda\"), xi.shape))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    avg_loss = train_one_epoch(epoch_number, \"writer\", train_dl, optimizer, loss_fn)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dl):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels) / vinputs.shape[0]\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1) \n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    epoch_number += 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dl):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        outputs = model(inputs)\n",
    "        print(outputs.detach().to(\"cpu\").numpy(), labels.detach().to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0118, -0.0108,  0.0058,  ...,  0.0058,  0.0030,  0.0047],\n",
      "        [ 0.0059,  0.0063, -0.0077,  ...,  0.0031,  0.0070,  0.0044],\n",
      "        [-0.0090,  0.0068,  0.0027,  ..., -0.0026,  0.0033, -0.0075],\n",
      "        ...,\n",
      "        [-0.0022, -0.0079,  0.0012,  ..., -0.0086,  0.0008, -0.0007],\n",
      "        [ 0.0047,  0.0080,  0.0099,  ..., -0.0008,  0.0015,  0.0003],\n",
      "        [-0.0066, -0.0032, -0.0019,  ..., -0.0002,  0.0064,  0.0058]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0037,  0.0079, -0.0049, -0.0013, -0.0060, -0.0011, -0.0059, -0.0074,\n",
      "         0.0092,  0.0003,  0.0023, -0.0005,  0.0023,  0.0075,  0.0081,  0.0131,\n",
      "         0.0061, -0.0007, -0.0036, -0.0055,  0.0009, -0.0043,  0.0064,  0.0067,\n",
      "         0.0021, -0.0007, -0.0025, -0.0038, -0.0101, -0.0062,  0.0035, -0.0015,\n",
      "        -0.0019, -0.0007, -0.0024, -0.0053,  0.0043, -0.0020, -0.0054,  0.0084,\n",
      "         0.0039, -0.0064, -0.0081,  0.0058, -0.0035,  0.0050, -0.0108, -0.0071,\n",
      "        -0.0025, -0.0010,  0.0088,  0.0067, -0.0034, -0.0017, -0.0005,  0.0075,\n",
      "         0.0082,  0.0089,  0.0099,  0.0119, -0.0007,  0.0078,  0.0010,  0.0069,\n",
      "        -0.0066,  0.0079, -0.0010, -0.0020,  0.0035,  0.0106, -0.0024,  0.0082,\n",
      "         0.0129,  0.0083,  0.0024, -0.0011,  0.0099,  0.0016,  0.0061,  0.0081,\n",
      "         0.0087,  0.0036, -0.0055, -0.0049,  0.0091,  0.0007, -0.0050,  0.0049,\n",
      "         0.0013,  0.0091, -0.0048, -0.0040,  0.0041, -0.0016,  0.0022,  0.0079,\n",
      "         0.0059, -0.0026, -0.0056,  0.0100,  0.0008, -0.0034,  0.0041, -0.0038,\n",
      "         0.0016,  0.0059,  0.0122, -0.0014,  0.0058,  0.0077,  0.0088, -0.0057,\n",
      "        -0.0090, -0.0102, -0.0065, -0.0004,  0.0010,  0.0021,  0.0084,  0.0048,\n",
      "         0.0024,  0.0034,  0.0047,  0.0085,  0.0122,  0.0029,  0.0108,  0.0119,\n",
      "         0.0041,  0.0101,  0.0112,  0.0017, -0.0040,  0.0132,  0.0028,  0.0029,\n",
      "         0.0122,  0.0089,  0.0043,  0.0007, -0.0059,  0.0048,  0.0107,  0.0080,\n",
      "         0.0109,  0.0039, -0.0078,  0.0099, -0.0059, -0.0071, -0.0074,  0.0117,\n",
      "        -0.0004, -0.0026, -0.0061,  0.0055,  0.0080,  0.0022, -0.0069,  0.0075,\n",
      "        -0.0043,  0.0087, -0.0030,  0.0061,  0.0131, -0.0068, -0.0046,  0.0010,\n",
      "         0.0044,  0.0059,  0.0057,  0.0038,  0.0093, -0.0080,  0.0032,  0.0087,\n",
      "        -0.0086, -0.0046, -0.0086, -0.0012, -0.0035,  0.0072,  0.0034, -0.0002,\n",
      "         0.0115,  0.0126,  0.0050,  0.0065, -0.0012, -0.0114, -0.0021, -0.0028,\n",
      "         0.0002, -0.0047, -0.0082,  0.0057,  0.0025, -0.0047, -0.0021, -0.0052,\n",
      "        -0.0050, -0.0030,  0.0037,  0.0015,  0.0048, -0.0002,  0.0030, -0.0009,\n",
      "         0.0022,  0.0106,  0.0126,  0.0075, -0.0080, -0.0015,  0.0063, -0.0047,\n",
      "         0.0080,  0.0034, -0.0079, -0.0036, -0.0032,  0.0035,  0.0067,  0.0096,\n",
      "        -0.0055,  0.0049,  0.0028, -0.0113,  0.0066,  0.0090,  0.0097,  0.0030,\n",
      "         0.0005, -0.0052,  0.0120,  0.0005, -0.0005,  0.0026, -0.0050, -0.0023,\n",
      "        -0.0106, -0.0063,  0.0081, -0.0008,  0.0016, -0.0032,  0.0022, -0.0030,\n",
      "         0.0129,  0.0099, -0.0053,  0.0077,  0.0127,  0.0057, -0.0028,  0.0050],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0009, -0.0363, -0.0381,  ..., -0.0401,  0.0380,  0.0099],\n",
      "        [ 0.0065, -0.0434, -0.0493,  ..., -0.0244, -0.0562, -0.0024],\n",
      "        [ 0.0412,  0.0561,  0.0184,  ..., -0.0130,  0.0038, -0.0457],\n",
      "        ...,\n",
      "        [ 0.0060, -0.0048, -0.0385,  ...,  0.0080, -0.0081,  0.0321],\n",
      "        [-0.0016,  0.0501,  0.0636,  ...,  0.0506, -0.0266, -0.0004],\n",
      "        [ 0.0089,  0.0538,  0.0339,  ..., -0.0281,  0.0127,  0.0235]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0149, -0.0250, -0.0096, -0.0339,  0.0029,  0.0202,  0.0604, -0.0411,\n",
      "        -0.0046, -0.0052, -0.0148, -0.0296, -0.0383, -0.0402, -0.0133,  0.0308,\n",
      "         0.0288,  0.0383,  0.0413, -0.0065, -0.0400,  0.0132, -0.0472,  0.0072,\n",
      "        -0.0406,  0.0497,  0.0291, -0.0178,  0.0406, -0.0399,  0.0174,  0.0359,\n",
      "        -0.0274, -0.0252,  0.0266, -0.0411,  0.0426, -0.0300,  0.0507, -0.0032,\n",
      "         0.0035, -0.0179, -0.0240,  0.0317, -0.0544,  0.0466, -0.0047,  0.0155,\n",
      "        -0.0438, -0.0114,  0.0468,  0.0086, -0.0585,  0.0621, -0.0371,  0.0096,\n",
      "        -0.0030, -0.0247,  0.0584,  0.0256, -0.0091, -0.0288,  0.0296,  0.0005,\n",
      "         0.0336, -0.0457, -0.0607, -0.0520,  0.0325,  0.0450,  0.0283,  0.0305,\n",
      "        -0.0590,  0.0281,  0.0487,  0.0291,  0.0229,  0.0246, -0.0621,  0.0500,\n",
      "        -0.0330, -0.0176, -0.0293, -0.0237, -0.0445,  0.0220, -0.0306, -0.0189,\n",
      "        -0.0386, -0.0451, -0.0628, -0.0231,  0.0436,  0.0168, -0.0236,  0.0645,\n",
      "        -0.0517, -0.0422, -0.0391, -0.0492, -0.0438,  0.0137, -0.0200,  0.0391,\n",
      "        -0.0503, -0.0556, -0.0349,  0.0493,  0.0015,  0.0589, -0.0182,  0.0106,\n",
      "        -0.0129, -0.0437,  0.0577,  0.0164,  0.0041, -0.0002, -0.0555,  0.0318,\n",
      "         0.0298,  0.0158, -0.0164, -0.0466, -0.0416,  0.0571, -0.0081, -0.0104,\n",
      "         0.0010,  0.0554,  0.0388,  0.0336, -0.0154,  0.0611, -0.0561,  0.0108,\n",
      "         0.0151,  0.0294,  0.0436,  0.0432,  0.0202, -0.0542,  0.0443, -0.0298,\n",
      "        -0.0480,  0.0532, -0.0022,  0.0195,  0.0471, -0.0457, -0.0269,  0.0178,\n",
      "         0.0528,  0.0591, -0.0225, -0.0341, -0.0072,  0.0422, -0.0317, -0.0077,\n",
      "        -0.0184,  0.0357, -0.0115,  0.0178, -0.0176, -0.0262,  0.0033,  0.0399,\n",
      "        -0.0481, -0.0546,  0.0581,  0.0047,  0.0099, -0.0551, -0.0322,  0.0394,\n",
      "         0.0427,  0.0100, -0.0320, -0.0306, -0.0487, -0.0510,  0.0375, -0.0122,\n",
      "        -0.0486,  0.0238, -0.0074,  0.0449,  0.0035, -0.0427, -0.0585, -0.0620,\n",
      "        -0.0315, -0.0493, -0.0247,  0.0279,  0.0624,  0.0217,  0.0297, -0.0457,\n",
      "         0.0407,  0.0536,  0.0460, -0.0489, -0.0434, -0.0566,  0.0014,  0.0486,\n",
      "         0.0257,  0.0581,  0.0067, -0.0054, -0.0456, -0.0248,  0.0008,  0.0620,\n",
      "        -0.0035,  0.0499, -0.0179,  0.0105,  0.0535, -0.0499, -0.0294, -0.0346,\n",
      "         0.0342, -0.0503,  0.0537, -0.0292,  0.0518, -0.0481, -0.0388, -0.0261,\n",
      "        -0.0350, -0.0469,  0.0195, -0.0496, -0.0604, -0.0089, -0.0057, -0.0521,\n",
      "        -0.0367, -0.0322, -0.0256, -0.0632, -0.0506, -0.0404, -0.0340, -0.0240,\n",
      "        -0.0090, -0.0152,  0.0009, -0.0264,  0.0593,  0.0179, -0.0047,  0.0186],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0434,  0.0074,  0.0566,  ...,  0.0298,  0.0208,  0.0260],\n",
      "        [-0.0365, -0.0130,  0.0254,  ..., -0.0147, -0.0109, -0.0042],\n",
      "        [ 0.0266, -0.0625, -0.0332,  ...,  0.0366, -0.0526,  0.0327],\n",
      "        ...,\n",
      "        [-0.0315,  0.0563,  0.0442,  ...,  0.0257,  0.0398,  0.0543],\n",
      "        [-0.0455, -0.0471,  0.0156,  ..., -0.0020,  0.0151, -0.0268],\n",
      "        [ 0.0524, -0.0521,  0.0372,  ..., -0.0568,  0.0233, -0.0398]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 8.4363e-03,  1.6172e-02, -1.0725e-02, -6.6446e-04,  3.7997e-02,\n",
      "        -4.6086e-03,  6.5228e-02, -4.5277e-03,  6.2183e-02, -5.8285e-02,\n",
      "        -1.6135e-02, -1.6876e-03,  3.4993e-02, -5.7856e-02,  1.1907e-02,\n",
      "         5.9353e-02,  3.6765e-02,  5.8424e-02, -3.5211e-02,  4.1802e-02,\n",
      "        -3.4115e-02, -2.0579e-02,  4.3477e-02, -4.2672e-02, -3.8701e-02,\n",
      "        -4.4783e-03,  5.8163e-02, -2.7263e-02,  5.2605e-02, -1.1300e-02,\n",
      "        -2.8547e-02,  1.7623e-02,  4.4801e-02,  5.2454e-02, -5.0791e-03,\n",
      "         1.8207e-02, -3.5984e-02, -1.6067e-02, -2.1477e-02, -5.5593e-02,\n",
      "         5.0735e-02,  5.2889e-02,  2.0642e-02,  3.1446e-03,  3.3868e-02,\n",
      "        -5.5295e-02,  4.0467e-02, -5.8890e-02, -5.8429e-02, -3.1903e-02,\n",
      "         1.3391e-02,  2.8038e-02, -3.2032e-02,  1.0003e-02, -6.1403e-02,\n",
      "        -4.0619e-02,  4.4912e-02,  3.8686e-02, -5.1096e-02, -5.8669e-02,\n",
      "         4.8231e-02,  3.7344e-02,  1.7994e-02, -4.3989e-02, -2.1553e-02,\n",
      "         4.1549e-02,  5.7760e-02, -3.9742e-02,  1.9774e-02, -5.2448e-02,\n",
      "        -1.9037e-02,  3.3862e-02, -2.4061e-02, -2.3391e-02, -2.7041e-02,\n",
      "        -1.5695e-02, -2.4966e-02, -3.1186e-03, -1.0108e-02, -4.6115e-02,\n",
      "        -5.4592e-02,  4.9038e-02, -4.2915e-02,  1.5927e-02, -5.1578e-02,\n",
      "        -3.4989e-02, -4.9217e-02, -4.7412e-02, -2.3421e-02, -1.4324e-02,\n",
      "         9.6957e-03,  5.8087e-02,  3.9996e-02, -5.3694e-02, -4.4376e-02,\n",
      "        -6.0183e-02, -5.3347e-02,  3.4347e-02,  2.1924e-02,  5.0922e-02,\n",
      "         2.5476e-02,  3.0783e-02,  1.5363e-02, -5.4965e-02,  2.4077e-02,\n",
      "         1.0808e-02,  3.6709e-02,  2.0359e-04,  4.3326e-02, -3.6481e-02,\n",
      "         3.7535e-02, -6.0225e-03, -8.3613e-03, -2.7068e-02,  1.9997e-02,\n",
      "         4.5590e-02, -5.1705e-02, -1.7862e-03, -3.3710e-02, -3.7740e-02,\n",
      "        -5.3065e-02, -2.5912e-02,  4.5245e-02, -2.8560e-02, -2.3959e-02,\n",
      "        -5.8232e-02, -2.9661e-02,  3.5570e-02, -3.7872e-02,  5.8355e-02,\n",
      "        -2.2179e-02, -5.3552e-04, -4.3962e-02,  4.8701e-03,  5.7326e-02,\n",
      "         5.3015e-02,  5.0296e-02,  1.3626e-02, -2.7465e-02, -2.0527e-02,\n",
      "         3.6915e-02,  4.6944e-02,  5.2864e-02, -3.7740e-02, -1.3514e-02,\n",
      "         5.9519e-02, -1.5580e-02,  2.1077e-02,  1.3603e-02, -3.3107e-02,\n",
      "        -6.4054e-03,  5.1914e-02, -5.4262e-02, -3.3450e-02,  1.3311e-02,\n",
      "        -8.7211e-03,  5.0107e-02,  2.4743e-02, -1.4662e-02, -5.4191e-02,\n",
      "        -9.7314e-03,  5.8208e-02,  3.5826e-02,  1.6920e-03, -4.7270e-02,\n",
      "         2.6714e-02, -3.0036e-02, -8.2388e-03, -3.4315e-02, -1.7300e-02,\n",
      "         5.5189e-02, -9.7970e-03,  4.3824e-02, -3.8531e-03,  3.4657e-02,\n",
      "         5.2884e-02,  5.9519e-02,  7.7688e-03,  3.6705e-02,  4.7083e-02,\n",
      "         5.3490e-03,  7.3613e-03,  8.5329e-03,  2.8249e-02,  7.6249e-05,\n",
      "         4.3757e-02,  4.9280e-02,  4.9505e-02,  1.3728e-02,  5.8177e-02,\n",
      "        -2.9718e-02,  4.5491e-02,  4.3224e-02,  6.1374e-02,  2.5287e-02,\n",
      "         1.1513e-02, -3.1961e-03,  7.7035e-03,  3.6991e-02,  2.4673e-02,\n",
      "         3.8204e-02, -1.8569e-02, -5.4871e-02,  2.4003e-02,  4.9540e-02,\n",
      "         1.0243e-02,  6.3875e-02, -6.2000e-05,  3.5100e-02, -7.8961e-03,\n",
      "        -6.6379e-03,  3.7351e-02, -2.6555e-02, -8.9399e-03,  2.0414e-02,\n",
      "         5.1492e-02, -1.1818e-02, -4.0824e-02,  3.6047e-02, -4.2673e-02,\n",
      "        -2.3347e-02,  5.5530e-02,  3.6603e-02,  5.9564e-02,  1.8963e-02,\n",
      "         5.3433e-02,  6.9504e-03, -6.2521e-04,  3.7455e-02, -1.3696e-02,\n",
      "         3.2307e-02,  5.3057e-02, -6.0146e-03, -1.9535e-02, -1.3003e-02,\n",
      "         1.9106e-02,  4.1445e-02,  1.9106e-02,  1.2226e-02,  6.0092e-02,\n",
      "        -2.5856e-02, -5.5456e-02, -1.2794e-02, -1.9094e-03, -6.3916e-02,\n",
      "        -3.0426e-02,  4.8742e-02, -3.8670e-02, -2.0931e-02, -6.4415e-03,\n",
      "        -1.4425e-02,  4.3302e-02, -4.3328e-02, -4.0051e-02,  2.5027e-02,\n",
      "         5.7509e-02], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0375,  0.0011, -0.0383,  ..., -0.0269, -0.0595,  0.0360],\n",
      "        [ 0.0332,  0.0090,  0.0463,  ...,  0.0227,  0.0602, -0.0595],\n",
      "        [ 0.0453,  0.0201,  0.0518,  ...,  0.0414,  0.0159,  0.0318],\n",
      "        ...,\n",
      "        [-0.0620,  0.0456, -0.0367,  ..., -0.0067, -0.0200, -0.0635],\n",
      "        [-0.0281,  0.0624, -0.0285,  ..., -0.0352, -0.0428, -0.0142],\n",
      "        [ 0.0451, -0.0199, -0.0502,  ...,  0.0174,  0.0228,  0.0053]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0035, -0.0029,  0.0271, -0.0045,  0.0211, -0.0506,  0.0592, -0.0461,\n",
      "        -0.0274, -0.0328, -0.0582,  0.0024,  0.0501,  0.0463, -0.0586,  0.0205,\n",
      "         0.0497,  0.0218,  0.0638, -0.0020,  0.0102, -0.0551,  0.0285, -0.0231,\n",
      "        -0.0280, -0.0218,  0.0372,  0.0348, -0.0092, -0.0373,  0.0306, -0.0137,\n",
      "         0.0158, -0.0397, -0.0270, -0.0519,  0.0042, -0.0515, -0.0007,  0.0350,\n",
      "         0.0059, -0.0017,  0.0555, -0.0227, -0.0265,  0.0405, -0.0429, -0.0098,\n",
      "         0.0218, -0.0103, -0.0341,  0.0616,  0.0306, -0.0177,  0.0434,  0.0111,\n",
      "        -0.0201,  0.0182, -0.0590, -0.0276,  0.0216,  0.0209, -0.0017, -0.0438,\n",
      "        -0.0192, -0.0560, -0.0341,  0.0187,  0.0428,  0.0265,  0.0563,  0.0611,\n",
      "         0.0068,  0.0452,  0.0241,  0.0407, -0.0345,  0.0401,  0.0501,  0.0471,\n",
      "         0.0562,  0.0333, -0.0191, -0.0563, -0.0087, -0.0216, -0.0094, -0.0195,\n",
      "         0.0349,  0.0558, -0.0129,  0.0292, -0.0450, -0.0521, -0.0091, -0.0181,\n",
      "         0.0043, -0.0444, -0.0304, -0.0550,  0.0026, -0.0619,  0.0579,  0.0526,\n",
      "         0.0467,  0.0362, -0.0459,  0.0221, -0.0503, -0.0351, -0.0530,  0.0471,\n",
      "        -0.0175,  0.0470,  0.0011,  0.0539,  0.0176,  0.0328, -0.0205, -0.0406,\n",
      "        -0.0234, -0.0515,  0.0292, -0.0123, -0.0002,  0.0360, -0.0259,  0.0096],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0722,  0.0742, -0.0435,  ..., -0.0663,  0.0219,  0.0007],\n",
      "        [-0.0537,  0.0222,  0.0517,  ...,  0.0110,  0.0478,  0.0260],\n",
      "        [-0.0049, -0.0766, -0.0548,  ..., -0.0870,  0.0895,  0.0782],\n",
      "        ...,\n",
      "        [ 0.0875,  0.0421, -0.0609,  ..., -0.0064,  0.0158, -0.0105],\n",
      "        [-0.0574,  0.0434, -0.0883,  ...,  0.0419, -0.0434, -0.0071],\n",
      "        [ 0.0580, -0.0100, -0.0728,  ...,  0.0761, -0.0117,  0.0190]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0548, -0.0569,  0.0877, -0.0155, -0.0173,  0.0432,  0.0390,  0.0693,\n",
      "        -0.0041,  0.0775,  0.0760,  0.0216, -0.0792,  0.0367,  0.0063,  0.0837,\n",
      "        -0.0562, -0.0715,  0.0110,  0.0234, -0.0256,  0.0194,  0.0343, -0.0673,\n",
      "         0.0089,  0.0263, -0.0771, -0.0231, -0.0688,  0.0104, -0.0033,  0.0625,\n",
      "         0.0659,  0.0864,  0.0378,  0.0358, -0.0660, -0.0247,  0.0237, -0.0013,\n",
      "        -0.0200,  0.0782, -0.0263,  0.0184, -0.0250,  0.0753,  0.0680, -0.0524,\n",
      "        -0.0278,  0.0364, -0.0218, -0.0769, -0.0706, -0.0811, -0.0866,  0.0501,\n",
      "         0.0122,  0.0209, -0.0471, -0.0769,  0.0278,  0.0623, -0.0399, -0.0670,\n",
      "        -0.0768,  0.0755, -0.0329,  0.0083, -0.0412,  0.0140, -0.0042,  0.0172,\n",
      "         0.0327, -0.0340, -0.0658,  0.0809,  0.0756,  0.0094, -0.0777,  0.0506,\n",
      "        -0.0825, -0.0019,  0.0665,  0.0479,  0.0519,  0.0159,  0.0620, -0.0017,\n",
      "         0.0233, -0.0904,  0.0421,  0.0594,  0.0055, -0.0024, -0.0746,  0.0889,\n",
      "         0.0668,  0.0729,  0.0451, -0.0821,  0.0011,  0.0099,  0.0719, -0.0662,\n",
      "         0.0060, -0.0333,  0.0272,  0.0534, -0.0348, -0.0595,  0.0371, -0.0391,\n",
      "        -0.0254,  0.0090, -0.0425, -0.0135, -0.0875,  0.0449, -0.0799,  0.0093,\n",
      "        -0.0469,  0.0841,  0.0780, -0.0380,  0.0031,  0.0626,  0.0312, -0.0479],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0802, -0.0349,  0.0169,  ...,  0.0129, -0.0007,  0.0456],\n",
      "        [ 0.0520,  0.0614, -0.0110,  ...,  0.0306, -0.0139,  0.0520],\n",
      "        [-0.0485, -0.0851, -0.0461,  ...,  0.0643,  0.0027, -0.0300],\n",
      "        ...,\n",
      "        [ 0.0473,  0.0122,  0.0452,  ...,  0.0048,  0.0512, -0.0734],\n",
      "        [ 0.0460,  0.0829,  0.0111,  ..., -0.0561, -0.0548, -0.0353],\n",
      "        [ 0.0664, -0.0811,  0.0478,  ..., -0.0838, -0.0413, -0.0809]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0784, -0.0805,  0.0562,  0.0576,  0.0679, -0.0029, -0.0772,  0.0663,\n",
      "        -0.0094, -0.0387, -0.0484,  0.0583,  0.0772,  0.0056,  0.0667,  0.0282,\n",
      "        -0.0167, -0.0815,  0.0702,  0.0679, -0.0416, -0.0649,  0.0286,  0.0148,\n",
      "        -0.0759,  0.0597,  0.0438,  0.0783, -0.0396, -0.0479,  0.0134,  0.0868,\n",
      "        -0.0338, -0.0868, -0.0177,  0.0396,  0.0013, -0.0494, -0.0196,  0.0581,\n",
      "         0.0280, -0.0033, -0.0135, -0.0535,  0.0545, -0.0743,  0.0524, -0.0175,\n",
      "         0.0058,  0.0504, -0.0005, -0.0503, -0.0561,  0.0224,  0.0388, -0.0100,\n",
      "        -0.0549, -0.0320,  0.0634, -0.0015, -0.0284,  0.0846,  0.0747, -0.0664,\n",
      "        -0.0157,  0.0020, -0.0758,  0.0644,  0.0077, -0.0692,  0.0694,  0.0541,\n",
      "        -0.0758,  0.0671, -0.0613,  0.0571,  0.0088, -0.0534,  0.0179,  0.0844,\n",
      "        -0.0043,  0.0274, -0.0154,  0.0150,  0.0702, -0.0656,  0.0613,  0.0424,\n",
      "         0.0241,  0.0399,  0.0156,  0.0660,  0.0151,  0.0023,  0.0338, -0.0287,\n",
      "        -0.0301, -0.0465,  0.0584, -0.0347, -0.0607,  0.0854,  0.0756, -0.0768,\n",
      "        -0.0321,  0.0021, -0.0776,  0.0796,  0.0277,  0.0223, -0.0156, -0.0096,\n",
      "         0.0618, -0.0835, -0.0713,  0.0029,  0.0148, -0.0225,  0.0674, -0.0527,\n",
      "         0.0170,  0.0815, -0.0103, -0.0506, -0.0034,  0.0181, -0.0086, -0.0060],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0408,  0.0111, -0.0203,  ..., -0.0049, -0.0178, -0.0259],\n",
      "        [ 0.0459, -0.0098,  0.0736,  ..., -0.0236, -0.0246,  0.0371],\n",
      "        [ 0.0027, -0.0432, -0.0715,  ...,  0.0723,  0.0283,  0.0871],\n",
      "        ...,\n",
      "        [ 0.0481,  0.0821,  0.0600,  ...,  0.0027,  0.0793, -0.0398],\n",
      "        [-0.0762,  0.0639,  0.0671,  ..., -0.0417,  0.0783,  0.0660],\n",
      "        [-0.0006,  0.0784,  0.0231,  ..., -0.0699, -0.0204,  0.0003]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0074, -0.0224,  0.0504, -0.0267, -0.0691,  0.0436, -0.0514, -0.0481,\n",
      "         0.0016, -0.0420, -0.0231,  0.0340,  0.0183,  0.0692, -0.0849, -0.0637,\n",
      "         0.0819,  0.0470, -0.0446,  0.0858, -0.0694,  0.0750, -0.0494,  0.0241,\n",
      "         0.0223,  0.0143,  0.0735,  0.0212,  0.0201,  0.0567,  0.0710,  0.0127,\n",
      "        -0.0296,  0.0036,  0.0136,  0.0079,  0.0428, -0.0207,  0.0840, -0.0137,\n",
      "        -0.0184, -0.0305,  0.0571,  0.0275,  0.0528, -0.0206,  0.0741,  0.0869,\n",
      "         0.0617,  0.0265, -0.0099, -0.0687,  0.0077,  0.0509, -0.0444,  0.0468,\n",
      "        -0.0891,  0.0699, -0.0704, -0.0274, -0.0341, -0.0304,  0.0007, -0.0237],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1054,  0.0517,  0.0391,  ..., -0.0321,  0.1134,  0.0513],\n",
      "        [ 0.0950,  0.0428,  0.0333,  ...,  0.0791,  0.1019,  0.1009],\n",
      "        [-0.0866,  0.0354,  0.0329,  ..., -0.0534, -0.0234,  0.0550],\n",
      "        ...,\n",
      "        [-0.1179,  0.0581, -0.0841,  ..., -0.0017, -0.0248,  0.0147],\n",
      "        [ 0.0072,  0.0428, -0.1133,  ...,  0.0099,  0.0864, -0.0081],\n",
      "        [-0.0485,  0.0002, -0.0909,  ...,  0.1147, -0.0587, -0.1113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1152,  0.0726, -0.0713, -0.0311, -0.1036, -0.0760, -0.0372,  0.0588,\n",
      "         0.0317,  0.0087, -0.0904, -0.1127, -0.0362, -0.0597,  0.0941,  0.0267,\n",
      "         0.0336, -0.0477, -0.1258,  0.0572, -0.0295, -0.0037, -0.0690,  0.0187,\n",
      "        -0.0317, -0.0915,  0.1163,  0.0440, -0.0830,  0.1020,  0.0569, -0.0342,\n",
      "        -0.0113, -0.1204,  0.0315,  0.0584, -0.0868,  0.0872,  0.0637,  0.0011,\n",
      "         0.0122,  0.0324, -0.0068,  0.1043,  0.1000, -0.0768, -0.1239,  0.0694,\n",
      "        -0.0992,  0.0544,  0.0404, -0.1067, -0.0118,  0.0443, -0.0230,  0.0905,\n",
      "         0.1169,  0.1028,  0.0075,  0.0167,  0.0439, -0.0903,  0.0057, -0.0006],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0272, -0.1038, -0.0794,  ...,  0.0661,  0.1229,  0.0229],\n",
      "        [ 0.0433, -0.0957,  0.0921,  ..., -0.0652, -0.1220,  0.1173],\n",
      "        [ 0.0029, -0.0628,  0.0552,  ..., -0.0696,  0.0578, -0.1123],\n",
      "        ...,\n",
      "        [ 0.0319,  0.0327,  0.0658,  ..., -0.0184,  0.1078,  0.0446],\n",
      "        [-0.1049, -0.0753, -0.0267,  ...,  0.0973, -0.0635, -0.0504],\n",
      "        [ 0.0117, -0.0926,  0.0112,  ...,  0.0766, -0.0150,  0.1175]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0017,  0.0641,  0.1230,  0.0835,  0.1189, -0.0066, -0.0081,  0.0878,\n",
      "        -0.0493,  0.0530,  0.1024,  0.1050, -0.0587, -0.1095,  0.0648, -0.0687,\n",
      "         0.0289,  0.0751, -0.1208,  0.0690, -0.1100,  0.0552, -0.0129, -0.1180,\n",
      "         0.0661, -0.0258,  0.1126, -0.0610, -0.0837,  0.0017,  0.0764,  0.0213,\n",
      "         0.0292,  0.0767, -0.0269,  0.0105, -0.0400, -0.0543,  0.0444,  0.0017,\n",
      "        -0.0050, -0.0641, -0.0014, -0.0145,  0.1045, -0.0784, -0.0644, -0.1236,\n",
      "         0.0686, -0.0763,  0.0535, -0.0418, -0.0173, -0.1118, -0.0799,  0.0528,\n",
      "         0.0961, -0.0613,  0.1113,  0.0263,  0.0121, -0.0310, -0.0735, -0.0046],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0235,  0.0209,  0.1141, -0.0352, -0.0458,  0.1067,  0.0375, -0.0868,\n",
      "          0.1106, -0.0329,  0.1072,  0.0626,  0.0032, -0.0812, -0.1036,  0.0188,\n",
      "         -0.0279, -0.0699, -0.1221, -0.0369, -0.0816,  0.0663, -0.0603,  0.1251,\n",
      "          0.1057, -0.0182, -0.0562,  0.0182,  0.1178, -0.0735, -0.0894, -0.0078,\n",
      "         -0.0593, -0.0693,  0.0238, -0.0365,  0.0959,  0.0685, -0.0522,  0.0903,\n",
      "          0.0821, -0.0205, -0.0648,  0.0180, -0.0460, -0.0612, -0.0222, -0.0025,\n",
      "          0.0435, -0.1033, -0.0589, -0.1100, -0.0823, -0.0913, -0.0583,  0.1070,\n",
      "         -0.0774,  0.0840,  0.0138, -0.0414, -0.0251, -0.0773,  0.0857,  0.0707]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0625], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, parameters in enumerate(model.hidden.parameters()):\n",
    "    print(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
